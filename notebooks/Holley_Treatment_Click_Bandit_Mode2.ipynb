{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Holley_Treatment_Click_Bandit_Model.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Holley Click Bandit Model for Emails (Test Run)\n",
        "\n",
        "Adapted from JCOM's Click Bandit Model for Holley (company_1950).\n",
        "\n",
        "- A Bandit style model using Normal-Inverse-Gamma (NIG) formulation\n",
        "- Based on historical observations, we compute opens and clicks of each treatment\n",
        "- Thompson Sampling with (user, treatment, date) hash-based seed for deterministic randomness\n",
        "\n",
        "**Key Differences from JCOM:**\n",
        "- Dataset: `company_1950` (not `company_1925`)\n",
        "- Interaction table: `treatment_interaction` (not `email_interactions_table`)\n",
        "- Surface ID: `929` (not `817`)\n",
        "- Data window: Uses all available data (campaign started Dec 4, 2025)\n",
        "\n",
        "**This notebook is for testing/analysis only - no deployment.**"
      ],
      "metadata": {
        "id": "holley-header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "!pip install keyring keyrings.google-artifactregistry-auth\n",
        "!pip install -U auxia.prediction.colab --index-url https://asia-northeast1-python.pkg.dev/auxia-gcp/auxia-pip/simple/ --extra-index-url https://pypi.org/simple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery_storage\n",
        "from google.cloud import bigquery\n",
        "from google.colab import data_table\n",
        "from google.api_core import exceptions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "import-tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from auxia.prediction.colab import control_flow_magic\n",
        "from auxia.prediction.colab.algorithms.stats_utils import *\n",
        "from auxia.prediction.colab.algorithms.ml_utils import gen_binary_classification_reports\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery import magics"
      ],
      "metadata": {
        "id": "import-auxia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "check-ram"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration\n",
        "\n",
        "Holley-specific settings"
      ],
      "metadata": {
        "id": "config-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Holley configuration\n",
        "COMPANY_ID = \"1950\"\n",
        "COMPANY_DATASET = f\"company_{COMPANY_ID}\"\n",
        "SURFACE_ID = 929  # Holley's email surface\n",
        "\n",
        "# Data window - use all available data since campaign started Dec 4\n",
        "DATA_WINDOW_DAYS = 60  # Will use whatever is available within this window\n",
        "\n",
        "print(f\"Company: {COMPANY_ID}\")\n",
        "print(f\"Dataset: {COMPANY_DATASET}\")\n",
        "print(f\"Surface ID: {SURFACE_ID}\")"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "data-load-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_user_name = !gcloud config get-value account\n",
        "current_user_name = current_user_name[0].split('@')[0]\n",
        "assert current_user_name\n",
        "display(f'Detected user name {current_user_name}')"
      ],
      "metadata": {
        "id": "get-user"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load treatment history and interactions data.\n",
        "\n",
        "**Note**: Holley uses `treatment_interaction` table (not `email_interactions_table` like JCOM)"
      ],
      "metadata": {
        "id": "data-load-note"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df --project auxia-reporting\n",
        "\n",
        "WITH\n",
        "th as\n",
        "(\n",
        "  SELECT user_id, treatment_id, treatment_tracking_id, treatment_sent_timestamp, arm_id, surface_id, rank\n",
        "  FROM `auxia-gcp.company_1950.treatment_history_sent`\n",
        "  WHERE DATE(treatment_sent_timestamp) BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 60 DAY) AND DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)\n",
        "  AND request_source = \"LIVE\"\n",
        "),\n",
        "\n",
        "-- Holley uses treatment_interaction (not email_interactions_table)\n",
        "views as\n",
        "(\n",
        "  SELECT treatment_tracking_id, interaction_timestamp_micros\n",
        "  FROM `auxia-gcp.company_1950.treatment_interaction`\n",
        "  WHERE DATE(interaction_timestamp_micros) BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 60 DAY) AND DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)\n",
        "  AND interaction_type = \"VIEWED\"\n",
        "),\n",
        "\n",
        "clicks as\n",
        "(\n",
        "  SELECT DISTINCT treatment_tracking_id\n",
        "  FROM `auxia-gcp.company_1950.treatment_interaction`\n",
        "  WHERE DATE(interaction_timestamp_micros) BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 60 DAY) AND DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)\n",
        "  AND interaction_type = \"CLICKED\"\n",
        ")\n",
        "\n",
        "SELECT th.treatment_id, th.surface_id, count(distinct views.treatment_tracking_id) as n,\n",
        "count(distinct clicks.treatment_tracking_id) as clicks\n",
        "FROM\n",
        "th\n",
        "JOIN views\n",
        "ON th.treatment_tracking_id = views.treatment_tracking_id\n",
        "LEFT OUTER JOIN clicks\n",
        "ON th.treatment_tracking_id = clicks.treatment_tracking_id\n",
        "GROUP BY ALL\n",
        ";"
      ],
      "metadata": {
        "id": "load-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"ctr\"] = df[\"clicks\"]/df[\"n\"]"
      ],
      "metadata": {
        "id": "calc-ctr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of treatments: {len(df)}\")\n",
        "print(f\"Total opens: {df['n'].sum()}\")\n",
        "print(f\"Total clicks: {df['clicks'].sum()}\")\n",
        "print(f\"Overall CTR: {df['clicks'].sum() / df['n'].sum():.2%}\")\n",
        "print(f\"\\nCTR Statistics:\")\n",
        "df[\"ctr\"].describe()"
      ],
      "metadata": {
        "id": "ctr-stats"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 10 treatments by CTR:\")\n",
        "df.sort_values(\"ctr\", ascending=False).head(10)"
      ],
      "metadata": {
        "id": "top-treatments"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All treatments sorted by volume:\")\n",
        "df.sort_values(\"n\", ascending=False)"
      ],
      "metadata": {
        "id": "all-treatments"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data volume per treatment\n",
        "print(\"Treatments by open volume:\")\n",
        "print(f\"  >1000 opens: {len(df[df['n'] > 1000])} treatments\")\n",
        "print(f\"  100-1000 opens: {len(df[(df['n'] >= 100) & (df['n'] <= 1000)])} treatments\")\n",
        "print(f\"  <100 opens: {len(df[df['n'] < 100])} treatments (high variance)\")"
      ],
      "metadata": {
        "id": "volume-check"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NIG Implementation\n",
        "\n",
        "- Update rules based on input query\n",
        "- Thompson Sampling to generate sampled rewards"
      ],
      "metadata": {
        "id": "nig-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert df[\"ctr\"].max() <= 1, \"CTR should not exceed 1\""
      ],
      "metadata": {
        "id": "assert-ctr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from auxia.prediction.colab.algorithms.bandits import NormalInverseGammaClickBandit\n",
        "from auxia.prediction.colab import tensorflow_model\n",
        "from auxia.prediction.colab.tensorflow import tf_random"
      ],
      "metadata": {
        "id": "import-bandit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "click_bandit = NormalInverseGammaClickBandit(df, treatment_id_col=\"treatment_id\", click_col=\"clicks\", view_col=\"n\")\n",
        "click_bandit.update()\n",
        "print(f\"Bandit updated with {len(click_bandit.treatments)} treatments\")"
      ],
      "metadata": {
        "id": "create-bandit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_scaling = 1\n",
        "treatment_ids = tf.constant([str(t) for t in click_bandit.treatments])\n",
        "mean_vector = tf.cast(tf.constant([click_bandit.get_posterior_mean(t) for t in click_bandit.treatments]), tf.float32)\n",
        "stddev_vector = tf.cast(tf.constant([(x**0.5)*std_scaling if np.isfinite(x) else 0.1 for x in [click_bandit.get_posterior_variance(t) for t in click_bandit.treatments]]), tf.float32)"
      ],
      "metadata": {
        "id": "create-vectors"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert tf.reduce_min(stddev_vector).numpy() > 0, \"All stddev values must be positive\""
      ],
      "metadata": {
        "id": "assert-stddev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Posterior Statistics:\")\n",
        "print(f\"  Mean CTR range: {tf.reduce_min(mean_vector).numpy():.4f} - {tf.reduce_max(mean_vector).numpy():.4f}\")\n",
        "print(f\"  Stddev range: {tf.reduce_min(stddev_vector).numpy():.6f} - {tf.reduce_max(stddev_vector).numpy():.6f}\")"
      ],
      "metadata": {
        "id": "print-ranges"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show posterior parameters for each treatment\n",
        "posterior_df = pd.DataFrame({\n",
        "    'treatment_id': [str(t) for t in click_bandit.treatments],\n",
        "    'posterior_mean': mean_vector.numpy(),\n",
        "    'posterior_stddev': stddev_vector.numpy()\n",
        "})\n",
        "posterior_df = posterior_df.merge(df[['treatment_id', 'n', 'clicks', 'ctr']].astype({'treatment_id': str}), on='treatment_id')\n",
        "posterior_df.sort_values('posterior_mean', ascending=False)"
      ],
      "metadata": {
        "id": "posterior-df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].hist(mean_vector.numpy(), bins=20, edgecolor='black')\n",
        "axes[0].set_title(\"Posterior Mean CTR Distribution\")\n",
        "axes[0].set_xlabel(\"Mean CTR\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "\n",
        "axes[1].hist(stddev_vector.numpy(), bins=20, edgecolor='black')\n",
        "axes[1].set_title(\"Posterior Stddev Distribution\")\n",
        "axes[1].set_xlabel(\"Stddev\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "posterior-plots"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Lookup Tables"
      ],
      "metadata": {
        "id": "hashmap-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionary-like lookup tables for each value tensor\n",
        "default_mean = 0\n",
        "default_stddev = 0.05  # Higher stddev for unknown treatments = more exploration\n",
        "\n",
        "lookup_mean = tf.lookup.StaticHashTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(treatment_ids, mean_vector), default_value=default_mean)\n",
        "lookup_stddev = tf.lookup.StaticHashTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(treatment_ids, stddev_vector), default_value=default_stddev)\n",
        "\n",
        "print(f\"Lookup tables created with {len(treatment_ids)} treatments\")\n",
        "print(f\"Default mean (unknown treatments): {default_mean}\")\n",
        "print(f\"Default stddev (unknown treatments): {default_stddev}\")"
      ],
      "metadata": {
        "id": "create-lookup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Offline Metrics\n",
        "\n",
        "Evaluate model on validation set (last 3 days)"
      ],
      "metadata": {
        "id": "metrics-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use recent data for validation\n",
        "validation_date = datetime.datetime.now() - datetime.timedelta(days=3)\n",
        "validation_date = validation_date.strftime(\"%Y-%m-%d\")\n",
        "print(f\"Validation cutoff date: {validation_date}\")"
      ],
      "metadata": {
        "id": "validation-date"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%substitute %DATE_DASHES%=validation_date\n",
        "%%bigquery df_metrics --project auxia-reporting\n",
        "\n",
        "WITH\n",
        "th as\n",
        "(\n",
        "  SELECT user_id, treatment_id, treatment_tracking_id, treatment_sent_timestamp, arm_id, surface_id\n",
        "  FROM `auxia-gcp.company_1950.treatment_history_sent`\n",
        "  WHERE TIMESTAMP_TRUNC(treatment_sent_timestamp, DAY) > TIMESTAMP(\"%DATE_DASHES%\")\n",
        "  AND request_source = \"LIVE\"\n",
        "),\n",
        "\n",
        "views as\n",
        "(\n",
        "  SELECT treatment_tracking_id, interaction_timestamp_micros\n",
        "  FROM `auxia-gcp.company_1950.treatment_interaction`\n",
        "  WHERE TIMESTAMP_TRUNC(interaction_timestamp_micros, DAY) > TIMESTAMP(\"%DATE_DASHES%\")\n",
        "  AND interaction_type = \"VIEWED\"\n",
        "),\n",
        "\n",
        "clicks as\n",
        "(\n",
        "  SELECT DISTINCT treatment_tracking_id\n",
        "  FROM `auxia-gcp.company_1950.treatment_interaction`\n",
        "  WHERE TIMESTAMP_TRUNC(interaction_timestamp_micros, DAY) > TIMESTAMP(\"%DATE_DASHES%\")\n",
        "  AND interaction_type = \"CLICKED\"\n",
        ")\n",
        "\n",
        "SELECT th.*, CASE WHEN clicks.treatment_tracking_id IS NOT NULL THEN 1 ELSE 0 END AS clicked\n",
        "FROM\n",
        "th\n",
        "JOIN views\n",
        "ON th.treatment_tracking_id = views.treatment_tracking_id\n",
        "LEFT OUTER JOIN clicks\n",
        "ON th.treatment_tracking_id = clicks.treatment_tracking_id\n",
        ";"
      ],
      "metadata": {
        "id": "load-validation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation set size: {len(df_metrics)}\")\n",
        "print(f\"\\nClick distribution:\")\n",
        "print(df_metrics.clicked.value_counts())\n",
        "print(f\"\\nValidation CTR: {df_metrics.clicked.mean():.2%}\")"
      ],
      "metadata": {
        "id": "validation-stats"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics.head()"
      ],
      "metadata": {
        "id": "validation-head"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treatment_tensor = tf.constant(df_metrics.treatment_id.astype(\"str\"))\n",
        "user_tensor = tf.constant(df_metrics.user_id.astype(\"str\"))"
      ],
      "metadata": {
        "id": "create-tensors"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create hash seed: treatment:user@day\n",
        "user_treatment_concated = treatment_tensor + ':' + user_tensor + '@' + tf.strings.as_string(tf.math.floordiv(tf.timestamp(), 86400))"
      ],
      "metadata": {
        "id": "concat-tensors"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random samples from N(0,1)\n",
        "probabilities = tf_random.stateless_normal_batched(user_treatment_concated, 1)\n",
        "probabilities = tf.cast(probabilities, tf.float32)"
      ],
      "metadata": {
        "id": "gen-probs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Thompson Sampling scores: mean + stddev * N(0,1)\n",
        "val_scores = tf.add(\n",
        "    tf.multiply(probabilities, tf.expand_dims(lookup_stddev.lookup(treatment_tensor), 1)), \n",
        "    tf.expand_dims(lookup_mean.lookup(treatment_tensor), 1)\n",
        ")"
      ],
      "metadata": {
        "id": "calc-val-scores"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].hist(probabilities.numpy().flatten(), bins=50, edgecolor='black')\n",
        "axes[0].set_title(\"Random Samples N(0,1)\")\n",
        "axes[0].set_xlabel(\"Value\")\n",
        "\n",
        "axes[1].hist(val_scores.numpy().flatten(), bins=50, edgecolor='black')\n",
        "axes[1].set_title(\"Thompson Sampling Scores (mean + stddev * N(0,1))\")\n",
        "axes[1].set_xlabel(\"Score\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "score-plots"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Binary Classification Report (AUC, etc.):\")\n",
        "_ = gen_binary_classification_reports(df_metrics.clicked.values, val_scores.numpy().flatten())"
      ],
      "metadata": {
        "id": "gen-reports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing\n",
        "\n",
        "Test the model with simulated users to see treatment selection distribution"
      ],
      "metadata": {
        "id": "dev-testing-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treatment_df = df[[\"treatment_id\", \"surface_id\"]].astype(\"str\").drop_duplicates()\n",
        "print(f\"Unique treatments: {len(treatment_df)}\")\n",
        "treatment_df"
      ],
      "metadata": {
        "id": "treatment-df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BanditClickModel(tf.Module):\n",
        "  \"\"\"Thompson Sampling bandit model for email treatment selection.\"\"\"\n",
        "  \n",
        "  model_metadata = {\n",
        "      'output': {'supported_output_types': ['PER_USER_TREATMENT_SCORE']},\n",
        "      'tensorflow_contract': {\n",
        "        'inputs': {\n",
        "            'tensors': [\n",
        "                {\n",
        "                    'name': 'treatment_features',\n",
        "                    'single_tensor_type': 'CATEGORICAL_STRING_TYPE',\n",
        "                    'feature_source': 'TREATMENT_FEATURES',\n",
        "                    'feature_names': ['treatment_id'],\n",
        "                },\n",
        "                {\n",
        "                    'name': 'user_features',\n",
        "                    'single_tensor_type': 'CATEGORICAL_STRING_TYPE',\n",
        "                    'feature_source': 'USER_FEATURES',\n",
        "                    'feature_names': ['user_id'],\n",
        "                },\n",
        "            ]\n",
        "        },\n",
        "    },\n",
        "  }\n",
        "\n",
        "  def __init__(self, lookup_mean, lookup_stddev):\n",
        "    self.lookup_mean = lookup_mean\n",
        "    self.lookup_stddev = lookup_stddev\n",
        "\n",
        "  @tf.function(input_signature=(\n",
        "      tf.TensorSpec(dtype=tf.string, shape=(None, None, 1)),\n",
        "      tf.TensorSpec(dtype=tf.int64, shape=(None,)),\n",
        "      tf.TensorSpec(dtype=tf.string, shape=(None, 1)),\n",
        "  ))\n",
        "  def __call__(self, treatment_features, treatment_count, user_features):\n",
        "    treatment_indices = tf.where(tf.sequence_mask(treatment_count))\n",
        "    user_ids = tf.squeeze(user_features, axis=-1)\n",
        "\n",
        "    user_treatment_counts = treatment_count\n",
        "    user_ids_cart = tf.repeat(user_ids, user_treatment_counts, axis=0)\n",
        "    treatment_ids_cart = tf.gather_nd(\n",
        "        tf.squeeze(treatment_features, axis=-1),\n",
        "        treatment_indices)\n",
        "\n",
        "    scoring_means = self.lookup_mean.lookup(treatment_ids_cart)\n",
        "    scoring_stddevs = self.lookup_stddev.lookup(treatment_ids_cart)\n",
        "\n",
        "    # Hash seed: treatment:user@day (deterministic per user-treatment-day)\n",
        "    user_treatment_concated = treatment_ids_cart + ':' + user_ids_cart + '@' + tf.strings.as_string(tf.math.floordiv(tf.timestamp(), 86400))\n",
        "\n",
        "    # Thompson Sampling: score = mean + stddev * N(0,1)\n",
        "    probabilities = tf.reshape(tf_random.stateless_normal_batched(user_treatment_concated, 1), [-1])\n",
        "    probabilities = tf.cast(probabilities, tf.float32)\n",
        "    probabilities = tf.add(tf.multiply(probabilities, scoring_stddevs), scoring_means)\n",
        "\n",
        "    return tf.scatter_nd(treatment_indices, probabilities, tf.cast(tf.shape(treatment_features)[:2], tf.int64))"
      ],
      "metadata": {
        "id": "bandit-model-class"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and validate model with 10K simulated users\n",
        "print(\"Building model with 10,000 simulated users...\")\n",
        "model, y = tensorflow_model.build_validated_model(\n",
        "    BanditClickModel(lookup_mean, lookup_stddev), \n",
        "    user_features=pd.DataFrame([{'user_id': str(k)} for k in range(10000)]), \n",
        "    treatment_features=treatment_df\n",
        ")\n",
        "print(\"Model built successfully!\")"
      ],
      "metadata": {
        "id": "build-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample scores (first 5 users x all treatments):\")\n",
        "y.head()"
      ],
      "metadata": {
        "id": "model-output-head"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Which treatment would be selected for each user?\n",
        "selections = y.idxmax(axis=1).value_counts()\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "selections.plot(kind=\"bar\")\n",
        "plt.title(\"Treatment Selection Distribution (10K users)\")\n",
        "plt.xlabel(\"Treatment ID\")\n",
        "plt.ylabel(\"Users Selected\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nSelection counts:\")\n",
        "print(selections)"
      ],
      "metadata": {
        "id": "treatment-selection-plot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare selection % with actual CTR\n",
        "selection_pct = (selections / selections.sum() * 100).reset_index()\n",
        "selection_pct.columns = ['treatment_id', 'selection_pct']\n",
        "\n",
        "comparison = selection_pct.merge(\n",
        "    df[['treatment_id', 'n', 'clicks', 'ctr']].astype({'treatment_id': str}), \n",
        "    on='treatment_id'\n",
        ").sort_values('selection_pct', ascending=False)\n",
        "\n",
        "print(\"Selection % vs Actual CTR:\")\n",
        "comparison"
      ],
      "metadata": {
        "id": "selection-comparison"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "This notebook tested the NIG Thompson Sampling bandit model for Holley email treatments.\n",
        "\n",
        "**Key findings:**\n",
        "- Posterior parameters computed for each treatment\n",
        "- Model correctly balances exploration (high stddev) vs exploitation (high mean)\n",
        "- Treatments with higher CTR get selected more often\n",
        "\n",
        "**Next steps (when ready for production):**\n",
        "1. Accumulate more data (currently ~5 days)\n",
        "2. Deploy to TF Serving\n",
        "3. Monitor CTR improvement over time"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
